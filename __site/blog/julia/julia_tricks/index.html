<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">
   
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/hypertext.css">
<link rel="icon" href="/assets/favicon.png">

   <title>Hidden Julia Tricks: The Uncommonly Known</title>  
</head>
<body>
<header>
  <h1 style="color:#283747">software engineering</h1>
  <nav>
    <a href="/" class="current">Tags</a>
  | <a href="/blog/" >Notes</a>
  <hr/>
  </nav>
</header>


<!-- Content appended here -->
<div class="franklin-content"><h1 id="hidden_julia_tricks_the_uncommonly_known"><a href="#hidden_julia_tricks_the_uncommonly_known" class="header-anchor">Hidden Julia Tricks: The Uncommonly Known</a></h1>
<p>These are the Julia tricks that don&#39;t make it into most tutorials but can seriously level up your code. Some are subtle, some are powerful, all are surprisingly useful once you know them.</p>
<h2 id="generated_functions_compile-time_metaprogramming"><a href="#generated_functions_compile-time_metaprogramming" class="header-anchor"><ol>
<li><p>Generated Functions: Compile-Time Metaprogramming</p>
</li>
</ol>
</a></h2>
<p>Most people know about macros, but <strong>generated functions</strong> are Julia&#39;s secret weapon for performance.</p>
<h3 id="what_are_they"><a href="#what_are_they" class="header-anchor">What Are They?</a></h3>
<p>Generated functions let you write code that generates specialized code at compile time based on the <em>types</em> of arguments &#40;not values&#41;.</p>
<pre><code class="language-julia">@generated function unroll_sum&#40;x::NTuple&#123;N, T&#125;&#41; where &#123;N, T&#125;
    # This runs at COMPILE TIME
    # We can inspect N and generate custom code
    expr &#61; :&#40;x&#91;1&#93;&#41;
    for i in 2:N
        expr &#61; :&#40;&#36;expr &#43; x&#91;&#36;i&#93;&#41;
    end
    return expr
end

# Usage
unroll_sum&#40;&#40;1, 2, 3, 4&#41;&#41;  # Generates: x&#91;1&#93; &#43; x&#91;2&#93; &#43; x&#91;3&#93; &#43; x&#91;4&#93;</code></pre>
<p>The generated function creates a completely unrolled version for each tuple size. No loops at runtime&#33;</p>
<h3 id="why_this_is_amazing"><a href="#why_this_is_amazing" class="header-anchor">Why This Is Amazing</a></h3>
<ul>
<li><p><strong>Zero runtime overhead</strong>: The loop is eliminated at compile time</p>
</li>
<li><p><strong>Type-driven specialization</strong>: Different code for different types</p>
</li>
<li><p><strong>Better than macros</strong>: Macros operate on syntax, generated functions operate on types</p>
</li>
</ul>
<h3 id="real-world_example_custom_dot_product"><a href="#real-world_example_custom_dot_product" class="header-anchor">Real-World Example: Custom Dot Product</a></h3>
<pre><code class="language-julia">@generated function fast_dot&#40;a::NTuple&#123;N, T&#125;, b::NTuple&#123;N, T&#125;&#41; where &#123;N, T&#125;
    # Generate completely unrolled dot product
    terms &#61; &#91;:&#40;a&#91;&#36;i&#93; * b&#91;&#36;i&#93;&#41; for i in 1:N&#93;
    return :&#40;&#43;&#40;&#36;&#40;terms...&#41;&#41;&#41;
end

fast_dot&#40;&#40;1, 2, 3&#41;, &#40;4, 5, 6&#41;&#41;  # 32 &#40;1*4 &#43; 2*5 &#43; 3*6&#41;</code></pre>
<p>This generates code equivalent to <code>a&#91;1&#93;*b&#91;1&#93; &#43; a&#91;2&#93;*b&#91;2&#93; &#43; a&#91;3&#93;*b&#91;3&#93;</code> with no loops&#33;</p>
<h2 id="ol_start2_val_types_turn_values_into_types"><a href="#ol_start2_val_types_turn_values_into_types" class="header-anchor"><ol start="2">
<li><p>Val Types: Turn Values into Types</p>
</li>
</ol>
</a></h2>
<p><code>Val&#123;x&#125;</code> is a way to pass <em>values</em> as <em>type parameters</em>, enabling dispatch on values.</p>
<pre><code class="language-julia">function process&#40;::Val&#123;:fast&#125;&#41;
    println&#40;&quot;Using fast algorithm&quot;&#41;
    # fast implementation
end

function process&#40;::Val&#123;:accurate&#125;&#41;
    println&#40;&quot;Using accurate algorithm&quot;&#41;
    # accurate implementation
end

process&#40;Val&#40;:fast&#41;&#41;      # Dispatch based on the symbol&#33;
process&#40;Val&#40;:accurate&#41;&#41;</code></pre>
<h3 id="why_this_matters"><a href="#why_this_matters" class="header-anchor">Why This Matters</a></h3>
<ul>
<li><p><strong>Zero-cost abstraction</strong>: The choice happens at compile time</p>
</li>
<li><p><strong>Better than runtime if-else</strong>: No branching overhead</p>
</li>
<li><p><strong>Configuration without runtime cost</strong></p>
</li>
</ul>
<h3 id="practical_use_matrix_operations"><a href="#practical_use_matrix_operations" class="header-anchor">Practical Use: Matrix Operations</a></h3>
<pre><code class="language-julia">function compute&#40;A, ::Val&#123;:row_major&#125;&#41;
    # Optimized for row-major access
    for i in 1:size&#40;A, 1&#41;, j in 1:size&#40;A, 2&#41;
        # process A&#91;i, j&#93;
    end
end

function compute&#40;A, ::Val&#123;:col_major&#125;&#41;
    # Optimized for column-major access
    for j in 1:size&#40;A, 2&#41;, i in 1:size&#40;A, 1&#41;
        # process A&#91;i, j&#93;
    end
end</code></pre>
<p>The compiler generates different code for each version, no runtime checks&#33;</p>
<h2 id="ol_start3_broadcasting_fusion_one_loop_for_everything"><a href="#ol_start3_broadcasting_fusion_one_loop_for_everything" class="header-anchor"><ol start="3">
<li><p>Broadcasting Fusion: One Loop for Everything</p>
</li>
</ol>
</a></h2>
<p>Everyone knows <code>x .&#43; y</code>, but the real magic is <strong>fusion</strong>.</p>
<pre><code class="language-julia"># These all fuse into a SINGLE loop
result &#61; @. sqrt&#40;abs&#40;sin&#40;x&#41;&#41;&#41; &#43; cos&#40;y&#41;^2

# Equivalent to:
# for i in eachindex&#40;x, y&#41;
#     result&#91;i&#93; &#61; sqrt&#40;abs&#40;sin&#40;x&#91;i&#93;&#41;&#41;&#41; &#43; cos&#40;y&#91;i&#93;&#41;^2
# end</code></pre>
<h3 id="the_secret_sauce"><a href="#the_secret_sauce" class="header-anchor">The Secret Sauce</a></h3>
<p>Broadcasting operations are <strong>lazy</strong> until you actually need the result. Julia builds a fusion tree and then executes everything in one pass.</p>
<pre><code class="language-julia">x &#61; 1:1000000
y &#61; 1:1000000

# Bad: Creates 3 temporary arrays
result &#61; sqrt.&#40;abs.&#40;sin.&#40;x&#41;&#41;&#41; .&#43; cos.&#40;y&#41;.^2

# Good: Single loop, no temporaries
result &#61; @. sqrt&#40;abs&#40;sin&#40;x&#41;&#41;&#41; &#43; cos&#40;y&#41;^2</code></pre>
<h3 id="custom_broadcasting"><a href="#custom_broadcasting" class="header-anchor">Custom Broadcasting</a></h3>
<p>You can make your own types broadcastable:</p>
<pre><code class="language-julia">struct MyArray&#123;T&#125;
    data::Vector&#123;T&#125;
end

Base.broadcastable&#40;x::MyArray&#41; &#61; x.data
Base.size&#40;x::MyArray&#41; &#61; size&#40;x.data&#41;
Base.getindex&#40;x::MyArray, i&#41; &#61; x.data&#91;i&#93;

# Now it just works&#33;
a &#61; MyArray&#40;&#91;1, 2, 3&#93;&#41;
b &#61; a .&#43; 10  # &#91;11, 12, 13&#93;</code></pre>
<h2 id="ol_start4_the_mysterious_inbounds_and_simd"><a href="#ol_start4_the_mysterious_inbounds_and_simd" class="header-anchor"><ol start="4">
<li><p>The Mysterious <code>@inbounds</code> and <code>@simd</code></p>
</li>
</ol>
</a></h2>
<p>These macros tell Julia to optimize loops aggressively.</p>
<h3 id="inbounds_skip_bounds_checking"><a href="#inbounds_skip_bounds_checking" class="header-anchor"><code>@inbounds</code>: Skip Bounds Checking</a></h3>
<pre><code class="language-julia">function sum_unsafe&#40;x&#41;
    total &#61; 0.0
    @inbounds for i in eachindex&#40;x&#41;
        total &#43;&#61; x&#91;i&#93;  # No bounds check&#33;
    end
    return total
end</code></pre>
<p><strong>Warning</strong>: Use only when you&#39;re 100&#37; sure indices are valid. Otherwise, segfault city.</p>
<h3 id="simd_enable_simd_vectorization"><a href="#simd_enable_simd_vectorization" class="header-anchor"><code>@simd</code>: Enable SIMD Vectorization</a></h3>
<pre><code class="language-julia">function sum_simd&#40;x&#41;
    total &#61; 0.0
    @simd for i in eachindex&#40;x&#41;
        total &#43;&#61; x&#91;i&#93;
    end
    return total
end</code></pre>
<p>This tells LLVM &quot;this loop is safe to vectorize, go wild&#33;&quot;</p>
<blockquote>
<p><strong>What&#39;s happening under the hood with <code>@simd</code>?</strong> When you use <code>@simd</code>, Julia adds <strong>metadata</strong> to the LLVM IR telling the compiler &quot;this loop has no dependencies between iterations and is safe to vectorize.&quot; In the compilation pipeline:</p>
<ol>
<li><p><strong>Julia frontend</strong>: The <code>@simd</code> macro marks the loop with special flags</p>
</li>
<li><p><strong>LLVM IR generation</strong>: Julia emits IR with <code>&#33;llvm.loop.vectorize.enable</code> metadata attached to the loop</p>
</li>
<li><p><strong>LLVM optimization passes</strong>: The Loop Vectorizer pass sees this hint and tries to:</p>
<ul>
<li><p>Analyze if vectorization is safe &#40;with <code>@simd</code>, it trusts you that it is&#41;</p>
</li>
<li><p>Determine the vector width &#40;e.g., process 4 Float64s at once with AVX2, or 8 with AVX-512&#41;</p>
</li>
<li><p>Transform scalar operations into <strong>SIMD instructions</strong> &#40;like <code>vaddpd</code> for vectorized addition&#41;</p>
</li>
<li><p>Generate code that processes multiple elements per iteration</p>
</li>
</ul>
</li>
<li><p><strong>Code generation</strong>: Instead of <code>add rax, rdx</code> &#40;scalar add&#41;, you get <code>vaddpd ymm0, ymm1, ymm2</code> &#40;add 4 doubles in parallel&#41;</p>
</li>
</ol>
<p>The key: <code>@simd</code> removes safety checks that would prevent vectorization. Without it, LLVM might be too conservative. With it, LLVM can unroll the loop and use vector registers &#40;XMM, YMM, ZMM&#41; to process 2, 4, 8, or even 16 elements simultaneously. This is why <code>@simd</code> can give 2-4x speedups on simple loops - you&#39;re literally computing multiple results per CPU instruction&#33;</p>
</blockquote>
<h3 id="the_power_combo"><a href="#the_power_combo" class="header-anchor">The Power Combo</a></h3>
<pre><code class="language-julia">function ultra_fast_sum&#40;x&#41;
    total &#61; 0.0
    @inbounds @simd for i in eachindex&#40;x&#41;
        total &#43;&#61; x&#91;i&#93;
    end
    return total
end</code></pre>
<p>Can be <strong>2-4x faster</strong> than naive loops for simple operations.</p>
<h2 id="ol_start5_views_stop_allocating_slices"><a href="#ol_start5_views_stop_allocating_slices" class="header-anchor"><ol start="5">
<li><p><code>@views</code>: Stop Allocating Slices</p>
</li>
</ol>
</a></h2>
<p>Array slicing in Julia allocates by default:</p>
<pre><code class="language-julia">x &#61; rand&#40;1000&#41;
y &#61; x&#91;1:100&#93;  # Allocates new array&#33;</code></pre>
<p>Use <code>@views</code> to make slices non-allocating:</p>
<pre><code class="language-julia">y &#61; @views x&#91;1:100&#93;  # No allocation, just a view&#33;

# Or for a whole block:
@views begin
    a &#61; x&#91;1:100&#93;
    b &#61; x&#91;101:200&#93;
    c &#61; a .&#43; b  # Still works with broadcasting&#33;
end</code></pre>
<h3 id="why_this_matters__2"><a href="#why_this_matters__2" class="header-anchor">Why This Matters</a></h3>
<p>Views have almost zero overhead but avoid allocations. In hot loops, this is huge:</p>
<pre><code class="language-julia">function process_columns_bad&#40;A&#41;
    for j in 1:size&#40;A, 2&#41;
        col &#61; A&#91;:, j&#93;  # Allocates every iteration&#33;
        # process col
    end
end

function process_columns_good&#40;A&#41;
    @views for j in 1:size&#40;A, 2&#41;
        col &#61; A&#91;:, j&#93;  # Just a view, no allocation
        # process col
    end
end</code></pre>
<h2 id="ol_start6_let_blocks_not_just_for_scoping"><a href="#ol_start6_let_blocks_not_just_for_scoping" class="header-anchor"><ol start="6">
<li><p><code>let</code> Blocks: Not Just For Scoping</p>
</li>
</ol>
</a></h2>
<p>Most people think <code>let</code> is just for scoping variables, but it&#39;s also a secret performance tool.</p>
<h3 id="capturing_variables_in_closures"><a href="#capturing_variables_in_closures" class="header-anchor">Capturing Variables in Closures</a></h3>
<pre><code class="language-julia"># Bad: Captures reference to i
functions &#61; &#91;&#40;&#41; -&gt; i for i in 1:5&#93;
&#91;f&#40;&#41; for f in functions&#93;  # All return 5&#33; ðŸ˜±

# Good: let creates new binding
functions &#61; &#91;let i&#61;i; &#40;&#41; -&gt; i; end for i in 1:5&#93;
&#91;f&#40;&#41; for f in functions&#93;  # &#91;1, 2, 3, 4, 5&#93; âœ“</code></pre>
<h3 id="type_inference_helper"><a href="#type_inference_helper" class="header-anchor">Type Inference Helper</a></h3>
<p>Sometimes Julia&#39;s compiler gets confused. <code>let</code> can help:</p>
<pre><code class="language-julia"># Sometimes helps type inference
result &#61; let x &#61; complex_computation&#40;&#41;
    process&#40;x&#41;
end</code></pre>
<h2 id="ol_start7_multiple_return_values_are_tuples_use_it"><a href="#ol_start7_multiple_return_values_are_tuples_use_it" class="header-anchor"><ol start="7">
<li><p>Multiple Return Values Are Tuples &#40;Use It&#33;&#41;</p>
</li>
</ol>
</a></h2>
<p>Julia&#39;s multiple return syntax is just tuple unpacking sugar:</p>
<pre><code class="language-julia">function stats&#40;x&#41;
    return minimum&#40;x&#41;, maximum&#40;x&#41;, mean&#40;x&#41;
end

min_val, max_val, mean_val &#61; stats&#40;data&#41;</code></pre>
<p>But you can be clever with this:</p>
<pre><code class="language-julia"># Return named tuples for clarity
function stats&#40;x&#41;
    return &#40;min&#61;minimum&#40;x&#41;, max&#61;maximum&#40;x&#41;, mean&#61;mean&#40;x&#41;&#41;
end

s &#61; stats&#40;data&#41;
println&#40;s.min, s.max, s.mean&#41;  # Named access&#33;</code></pre>
<h3 id="splatting_returns"><a href="#splatting_returns" class="header-anchor">Splatting Returns</a></h3>
<pre><code class="language-julia">function bounds&#40;x&#41;
    return minimum&#40;x&#41;, maximum&#40;x&#41;
end

# Splat into function call
clamp.&#40;data, bounds&#40;data&#41;...&#41;  # Clamp to min/max</code></pre>
<h2 id="ol_start8_do_syntax_not_just_for_files"><a href="#ol_start8_do_syntax_not_just_for_files" class="header-anchor"><ol start="8">
<li><p><code>do</code> Syntax: Not Just For Files</p>
</li>
</ol>
</a></h2>
<p>Everyone sees <code>do</code> with file I/O:</p>
<pre><code class="language-julia">open&#40;&quot;file.txt&quot;, &quot;r&quot;&#41; do f
    read&#40;f, String&#41;
end</code></pre>
<p>But <code>do</code> works with <em>any</em> function that takes a function as its first argument&#33;</p>
<blockquote>
<p><strong>Wait, what&#39;s actually happening with <code>do</code>?</strong> The <code>do</code> syntax is pure syntactic sugar that moves the first function argument to <em>after</em> the function call. It&#39;s confusing at first, so let&#39;s break it down:</p>
<p><strong>Normal way</strong> &#40;function as first argument&#41;:</p>
</blockquote>
<pre><code class="language-julia">&gt; open&#40;f -&gt; read&#40;f, String&#41;, &quot;file.txt&quot;, &quot;r&quot;&#41;
&gt; #    ^^^^^^^^^^^^^^^^^^  first arg is a function
&gt;</code></pre>
<blockquote>
<p><strong>With <code>do</code> syntax</strong>:</p>
</blockquote>
<pre><code class="language-julia">&gt; open&#40;&quot;file.txt&quot;, &quot;r&quot;&#41; do f
&gt;     read&#40;f, String&#41;
&gt; end
&gt;</code></pre>
<blockquote>
<p>These are <strong>exactly equivalent</strong>&#33; The <code>do</code> block creates an anonymous function and moves it to the <em>first</em> argument position, shifting all other arguments left. The weird part: it looks like <code>f</code> appears &quot;after&quot; the function call, but it&#39;s actually the parameter of a function that gets passed as the <em>first</em> argument&#33;</p>
<p><strong>General pattern</strong>:</p>
</blockquote>
<pre><code class="language-julia">&gt; func&#40;arg1, arg2&#41; do x
&gt;     # body using x
&gt; end
&gt; 
&gt; # Is transformed into:
&gt; func&#40;x -&gt; begin
&gt;     # body using x
&gt; end, arg1, arg2&#41;
&gt;</code></pre>
<blockquote>
<p>So when you write <code>with_timing&#40;&#41; do ... end</code>, the <code>do</code> block becomes the first &#40;and only&#41; argument. When you write <code>map&#40;data&#41; do x ... end</code>, the <code>do</code> block becomes the first argument and <code>data</code> becomes the second. It&#39;s a way to make code with callbacks more readable - instead of deeply nested lambdas, you write the callback last, like a code block.</p>
</blockquote>
<h3 id="custom_control_flow"><a href="#custom_control_flow" class="header-anchor">Custom Control Flow</a></h3>
<pre><code class="language-julia">function with_timing&#40;f&#41;
    start &#61; time&#40;&#41;
    result &#61; f&#40;&#41;
    elapsed &#61; time&#40;&#41; - start
    println&#40;&quot;Took &#36;elapsed seconds&quot;&#41;
    return result
end

# Use it with do&#33;
result &#61; with_timing&#40;&#41; do
    # Long computation here
    sleep&#40;2&#41;
    42
end

# This is equivalent to:
# result &#61; with_timing&#40;&#40;&#41; -&gt; begin
#     sleep&#40;2&#41;
#     42
# end&#41;</code></pre>
<h3 id="higher-order_functions"><a href="#higher-order_functions" class="header-anchor">Higher-Order Functions</a></h3>
<pre><code class="language-julia"># Instead of:
map&#40;x -&gt; x^2 &#43; 2x &#43; 1, data&#41;

# You can write:
map&#40;data&#41; do x
    x^2 &#43; 2x &#43; 1
end

# Which transforms to:
# map&#40;x -&gt; x^2 &#43; 2x &#43; 1, data&#41;
# The do block becomes the FIRST argument, data shifts to second&#33;</code></pre>
<p>Much more readable for complex functions&#33;</p>
<h2 id="ol_start9_vs__dot__the_secret_alias"><a href="#ol_start9_vs__dot__the_secret_alias" class="header-anchor"><ol start="9">
<li><p><code>@.</code> vs <code>@__dot__</code>: The Secret Alias</p>
</li>
</ol>
</a></h2>
<p><code>@.</code> is actually an alias for <code>@__dot__</code>. Why care? Because you can use it in code generation:</p>
<pre><code class="language-julia">macro myfusion&#40;expr&#41;
    return :&#40;@__dot__ &#36;expr&#41;
end

@myfusion sqrt&#40;x&#41; &#43; sin&#40;y&#41;  # Fully broadcast&#33;</code></pre>
<h2 id="ol_start10_basekwdef_easy_struct_defaults"><a href="#ol_start10_basekwdef_easy_struct_defaults" class="header-anchor"><ol start="10">
<li><p><code>Base.@kwdef</code>: Easy Struct Defaults</p>
</li>
</ol>
</a></h2>
<p>Tired of writing constructors for default values?</p>
<pre><code class="language-julia"># Old way
struct Config
    learning_rate::Float64
    batch_size::Int
    epochs::Int
    
    Config&#40;;learning_rate&#61;0.001, batch_size&#61;32, epochs&#61;100&#41; &#61;
        new&#40;learning_rate, batch_size, epochs&#41;
end

# New way with @kwdef
Base.@kwdef struct Config
    learning_rate::Float64 &#61; 0.001
    batch_size::Int &#61; 32
    epochs::Int &#61; 100
end

# Use it
config &#61; Config&#40;&#41;  # All defaults
config &#61; Config&#40;epochs&#61;200&#41;  # Override one</code></pre>
<h2 id="ol_start11_eval_generate_methods_programmatically"><a href="#ol_start11_eval_generate_methods_programmatically" class="header-anchor"><ol start="11">
<li><p><code>@eval</code>: Generate Methods Programmatically</p>
</li>
</ol>
</a></h2>
<p>Need to create many similar methods? Use <code>@eval</code>:</p>
<pre><code class="language-julia">for op in &#91;:sin, :cos, :tan&#93;
    @eval begin
        function &#36;&#40;Symbol&#40;:my_, op&#41;&#41;&#40;x&#41;
            println&#40;&quot;Computing &#36;&#40;&#36;op&#41;&quot;&#41;
            return &#36;&#40;op&#41;&#40;x&#41;
        end
    end
end

# Now you have: my_sin, my_cos, my_tan
my_sin&#40;Ï€/2&#41;  # Prints &quot;Computing sin&quot; then returns 1.0</code></pre>
<h3 id="real_example_operator_overloading"><a href="#real_example_operator_overloading" class="header-anchor">Real Example: Operator Overloading</a></h3>
<pre><code class="language-julia">for op in &#91;:&#43;, :-, :*, :/&#93;
    @eval Base.&#36;op&#40;a::MyType, b::MyType&#41; &#61; MyType&#40;&#36;&#40;op&#41;&#40;a.value, b.value&#41;&#41;
end</code></pre>
<h2 id="ol_start12_invokelatest_dynamic_function_calls"><a href="#ol_start12_invokelatest_dynamic_function_calls" class="header-anchor"><ol start="12">
<li><p><code>invokelatest</code>: Dynamic Function Calls</p>
</li>
</ol>
</a></h2>
<p>When you define functions at runtime and need to call them:</p>
<pre><code class="language-julia">function make_function&#40;&#41;
    eval&#40;:&#40;new_func&#40;x&#41; &#61; x^2&#41;&#41;
end

make_function&#40;&#41;
# new_func&#40;5&#41;  # Might not work due to world age&#33;
Base.invokelatest&#40;new_func, 5&#41;  # âœ“ Works&#33;</code></pre>
<p>This bypasses Julia&#39;s &quot;world age&quot; mechanism for dynamic code.</p>
<h2 id="ol_start13_field_access_with_getproperty"><a href="#ol_start13_field_access_with_getproperty" class="header-anchor"><ol start="13">
<li><p>Field Access with <code>getproperty</code></p>
</li>
</ol>
</a></h2>
<p>You can customize dot syntax:</p>
<pre><code class="language-julia">struct LazyDict
    data::Dict&#123;Symbol, Any&#125;
end

function Base.getproperty&#40;d::LazyDict, name::Symbol&#41;
    data &#61; getfield&#40;d, :data&#41;
    if haskey&#40;data, name&#41;
        return data&#91;name&#93;
    else
        return missing
    end
end

d &#61; LazyDict&#40;Dict&#40;:x &#61;&gt; 10, :y &#61;&gt; 20&#41;&#41;
d.x  # 10
d.z  # missing &#40;instead of error&#33;&#41;</code></pre>
<h2 id="ol_start14_nospecialize_reduce_compilation_time"><a href="#ol_start14_nospecialize_reduce_compilation_time" class="header-anchor"><ol start="14">
<li><p><code>@nospecialize</code>: Reduce Compilation Time</p>
</li>
</ol>
</a></h2>
<p>For functions that don&#39;t need specialization on every type:</p>
<pre><code class="language-julia">function debug_print&#40;@nospecialize&#40;x&#41;&#41;
    println&#40;&quot;Debug: &quot;, x&#41;
end</code></pre>
<p>This tells Julia &quot;don&#39;t compile a specialized version for every type&quot;, reducing compile time. Great for debugging utilities and error handling.</p>
<h2 id="ol_start15_the_ans_variable_in_repl"><a href="#ol_start15_the_ans_variable_in_repl" class="header-anchor"><ol start="15">
<li><p>The <code>ans</code> Variable in REPL</p>
</li>
</ol>
</a></h2>
<p>In the REPL, <code>ans</code> always holds the last computed value:</p>
<pre><code class="language-julia">julia&gt; 2 &#43; 2
4

julia&gt; ans * 10
40

julia&gt; ans &#43; 5
45</code></pre>
<p>Great for interactive exploration&#33;</p>
<h2 id="ol_start16_code_warntype_colors_mean_things"><a href="#ol_start16_code_warntype_colors_mean_things" class="header-anchor"><ol start="16">
<li><p><code>@code_warntype</code> Colors Mean Things</p>
</li>
</ol>
</a></h2>
<p>When debugging performance:</p>
<pre><code class="language-julia">@code_warntype my_function&#40;args&#41;</code></pre>
<p><strong>Color meanings:</strong></p>
<ul>
<li><p>Blue/cyan: Well-typed &#40;good&#33;&#41;</p>
</li>
<li><p>Yellow: Union types &#40;okay-ish&#41;</p>
</li>
<li><p>Red: <code>Any</code> type &#40;bad&#33; performance killer&#33;&#41;</p>
</li>
</ul>
<p>This is your first tool for finding type instabilities.</p>
<h2 id="ol_start17_loopvectorizationturbo_nuclear_option"><a href="#ol_start17_loopvectorizationturbo_nuclear_option" class="header-anchor"><ol start="17">
<li><p><code>LoopVectorization.@turbo</code>: Nuclear Option</p>
</li>
</ol>
</a></h2>
<p>Want the fastest loops possible? Use LoopVectorization.jl:</p>
<pre><code class="language-julia">using LoopVectorization

function ultra_sum&#40;x&#41;
    total &#61; 0.0
    @turbo for i in eachindex&#40;x&#41;
        total &#43;&#61; x&#91;i&#93;
    end
    return total
end</code></pre>
<p><code>@turbo</code> combines <code>@inbounds</code>, <code>@simd</code>, loop reordering, and other dark magic. Can be <strong>5-10x faster</strong> than naive loops.</p>
<h2 id="ol_start18_symbols_are_singletons"><a href="#ol_start18_symbols_are_singletons" class="header-anchor"><ol start="18">
<li><p>Symbols Are Singletons</p>
</li>
</ol>
</a></h2>
<p>Symbols like <code>:my_symbol</code> are interned - there&#39;s only one copy in memory:</p>
<pre><code class="language-julia">:x &#61;&#61;&#61; :x  # true &#40;same object&#33;&#41;
&quot;x&quot; &#61;&#61; &quot;x&quot;  # true &#40;equal&#41;
&quot;x&quot; &#61;&#61;&#61; &quot;x&quot;  # false &#40;different objects&#41;</code></pre>
<p>This makes symbols great for dispatch and dictionaries. They&#39;re also faster to compare.</p>
<h2 id="the_meta-trick_read_the_manual"><a href="#the_meta-trick_read_the_manual" class="header-anchor">The Meta-Trick: Read the Manual</a></h2>
<p>Julia&#39;s documentation has gems hidden in plain sight. The Performance Tips section alone is worth multiple read-throughs. And <code>@which</code>, <code>@edit</code>, and <code>methods&#40;&#41;</code> let you learn from the standard library itself.</p>
<pre><code class="language-julia">@which sort&#40;&#91;1,2,3&#93;&#41;  # Shows you which method is called
@edit sort&#40;&#91;1,2,3&#93;&#41;   # Opens the source code&#33;
methods&#40;sort&#41;         # Shows all sort methods</code></pre>
<p>The best Julia code is written by people who read other people&#39;s Julia code. The standard library is an excellent teacher.</p>
<div class="page-foot">
    Contact me by <a href="mailto:skchu@wustl.edu">E-mail</a> | <a href="https://github.com/kchu25">Github</a> | <a href="https://www.linkedin.com/in/kchu1/">Linkedin</a>
    <br>
    This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.  Last modified: December 01, 2025.
    <br>
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>
